---
title: "Predicting customer response to Bank telemarketing campaign"
author: "Melisa Maidana, Steven Lio, Zheren Xu"
date: "11/26/2021"
output: 
  html_document:
      toc: true
bibliography: bank_marketing_refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(knitr)
library(kableExtra)
```

## Introduction

Telemarketing campaigns can be very expensive to institutions. 
The possibility to predict the likelihood of customer response can lead to more efficient strategies that reduce implementation costs and maximize the success rate.

The objective of this project is to identify which customers are more likely 
to respond positively to a telemarketing campaign and subscribe to a new product (a long-term deposit). 
To address the predictive question posed above, we plan to conduct an exploratory data analysis 
and build a machine learning model that can predict if a certain customer looks alike the target audience for this product.

## Data

The data set used in this project is related with direct marketing campaigns (phone calls) of a Portuguese banking institution [@moro2014data] can be found [here](http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip).

The data set contains 20 features, plus the desired target. 
Each row contains information of one client, including personal and banking attributes, 
and data related to the past interactions with the telemarketer.

The data set presents class imbalance, since only about 11% of the records are targeted as positive
(meaning that the customer responded to the telemarketing offer).

```{r load_eda_table, echo=FALSE, include = FALSE}
summary <- read_csv("../results/eda_summary_table.csv")
summary <- summary |>  # remove first column (index)
    select(-1) 
```

```{r eda_class_imbalance, echo=FALSE}
summary %>%
  kbl(caption = "Table 1. Summary of examples per customer response in the dataset. Class imbalance is observed.") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

```{r eda_boxplot, fig.align = 'center', echo=FALSE, fig.cap="Figure 1. Distribution of customer response per age.", out.width = '60%'}
knitr::include_graphics("../results/eda_boxplot_by_age.png")
```

## Model building and selection
Two models, Random Forest Classifier and Logistic Regression, have been trained under the following conditions:

  * 5-fold [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) results were used for model evaluation
  * accuracy, f1-score, recall rate, and precision were the metrics selected for model evaluation
  * model building process has been carried out in Python 3.9 with the [`scikit-learn`](https://scikit-learn.org/stable/) library
  * Preprocessing of training data:
    - Data was randomized and split based on 80% for training and 20% for testing.
    - All features can be classified into categorical or numeric features. No features were dropped.
    - Missing numeric values are filled using median. Missing values in categorical features are filled as "missing".
    - All numeric features are scaled using the mean and variance (Standardization)
    - All categorical features are transformed with One-Hot Encoding.
  * Parameters and hyper-parameters tuning.
    - To speed up the training process and ensure reproducibility, the value of `n_jobs` is set to `-1` and `random_state` to `123`.
    - The hyper-parameters are tuned by `RandomizedSearchCV` and the optimal parameter values are chosen based on f1-score.
    - The baseline accuracy of the model is 88.8% (obtained from the Dummy Classifier using highest frequency).

### Random Forest Classifier:
The best hyper-parameters for the Random Forest are:
```{r Load_RFC_params, echo=FALSE, include=FALSE}
RFC_BestParams <- read_csv("../results/RFC_BestParams.csv")
RFC_BestParams <- RFC_BestParams %>% select(-1) 
```
```{r RFC_params, echo=FALSE}
RFC_BestParams %>%
  kbl(caption = "Table 2. Best hyper-parameters for Random Forest Classifier.") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

```{r conmat_RFC, echo=FALSE, fig.align = 'center', fig.cap="Figure 2. Confusion matrix for Random Forest Classifier on Test data", out.width = '60%'}
knitr::include_graphics("../results/BestRandomForest_ConMat_Test.jpg")
```

```{r RFC_scores, echo=FALSE}
tibble(Accuracy="82.9%",
       Precision="39.7%",
       Recall="96.4%",
       f1="56.2%") %>%
  kbl(caption = "Table 3. Best Random Forest Classifier model scores on validation set:") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```
Random Forest Classifiers trained with the best parameters from hyper-parameter optimization gives relatively decent scores on the prediction on validation data. Even though
precision is low, it achieved an excellent recall score.

### Logistic Regression:
```{r Load_LR_params, echo=FALSE, include=FALSE}
LR_BestParams <- read_csv("../results/LR_BestParams.csv")
LR_BestParams <- LR_BestParams %>% select(-1) 
```
```{r LR_params, echo=FALSE}
LR_BestParams %>%
  kbl(caption = "Table 4. Best hyper-parameters for Logistic Regression Classifier.") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

```{r conmat_LR, echo=FALSE, fig.align = 'center', fig.cap="Figure 3. Confusion matrix for Logistic Regression on Test data", out.width = '60%'}
knitr::include_graphics("../results/BestLogisticRegression_ConMat_Test.jpg")
```

```{r LR_scores, echo=FALSE}
tibble(Accuracy="86.1%",
       Precision="44.6%",
       Recall="90.3%",
       f1="59.7%") %>%
  kbl(caption = "Table 5. Best Logistic Regression Classifier model scores on validation set:") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```
Logistic Regression overall performs better than the Random Forest Classifier. 

From the results above, we conclude that the Logistic Regression model will be 
the best for predicting customer response to the telemarketing campaign. 
In addition, it provides more interpretable results through the features coefficients.


## Analysis and Results Discussion


```{r load_coef_table, echo=FALSE, include = FALSE}
lr_coeff <- read_csv("../results/BestLogisticRegression_Coefficients.csv") %>% arrange(desc(Coefficient))
colnames(lr_coeff) <- c("Feature","Coefficient")
lr_coeff
```
```{r coeff_barplot, echo=FALSE, fig.align = 'center', fig.cap="Figure 4. Top 10 Coefficients from Logistics Regression Model", out.width = '60%'}
ggplot(lr_coeff[1:10,], aes(x=Coefficient, y=reorder(Feature, Coefficient), fill=Coefficient)) +
  geom_bar(stat="identity", show.legend = FALSE) +
  geom_text(aes(label=round(Coefficient,2)), hjust = 1.3, color="white", size=5.0) +
  theme_classic() +
  labs(x="Features",
       y="Coefficient Values",
       title="Top 10 Coefficients") +
  theme(plot.title=element_text(hjust=0.5, face="bold"),
        axis.title.x=element_text(face="bold"),
        axis.title.y=element_text(face="bold"))
```

As shown in Figure 4, `duration` and `month_mar` have the highest coefficient 
value in the final model. `duration` corresponds to the duration of the call in seconds and 
`month_mar` corresponds to customer whose last contact date occurred during March. 
We can also see that the campaign achieved better response rates in August and October.

`poutcome_success` indicates previous success with marketing campaign and is tied to the 
idea that a customer that accepted a telemarking offer in the past may be more likely to
 accept a new one again.

Finally another interesting feature is `cons.price.idx`, which shows up as 
the 3rd more important variable learned by the model. The Consumer Price Index is a quarterly
updated variable that indicates the changes in prices as experienced by consumers. 
When this index is high, then customers may be more open to switch to a new product
for a better price. Even though this may lower the revenue per customer, it still may be
a desired objective for other reasons, such as customer retention. 


### Limitations

Many of the most important features identified by the model, such as the month of contact 
or the duration of the call, are unknown for customers that had no record of previous interactions with the bank. 
However, once this information has been collected the prediction becomes very accurate.
Moreover, we believe that including the reason of last contact in the data gathering process would 
add valuable information and increase the accuracy of the model.

Lastly, we lack of context on the campaign schedule and other environment variables, 
so at this point we cannot make any inferences regarding the months with better success rates.


### Conclusions

Overall the model has stable accuracy and recall rate. Hence with the correct
variables, the model can identify those who will be likely to response to the telemarketing
campaign. 
Some additional features, such as reason of last contact, could bring additional value to the model
and improve the False Positive rate.

The model developed provides flexibility to prioritize the customers by likelihood of success 
until we reach a desired target or budget. Although, we also recommend to assign weight to the customers
based on their banking/personal profile. 
This categorization should be defined by the bank and 
must be aligned with the objective of the particular campaign. 


## References
