---
title: "Predicting customer response to Bank telemarketing campaign"
author: "Melisa Maidana, Steven Lio, Zheren Xu"
date: "11/26/2021"
output: 
  html_document:
      toc: true
bibliography: bank_marketing_refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(knitr)
library(kableExtra)
```

## Introduction

Telemarketing campaigns can be very expensive to institutions. 
The possibility to predict the likelihood of customer response can lead to more efficient strategies that reduce implementation costs and maximize the success rate.

The objective of this project is to identify which customers are more likely 
to respond positively to a telemarketing campaign and subscribe to a new product (a long-term deposit). 
Specifically, if a customer is contacted over the phone, will they subscribe to the new product being offered?

To address the predictive question posed above, we conducted an exploratory data analysis 
and built a machine learning model to predict if a certain customer would subscribe to the new product.

## Data

The data set used in this project is related to direct marketing campaigns (phone calls) of a Portuguese banking institution [@moro2014data] can be found [here](http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip).

The data set contains 20 features, plus the desired target. 
Each row contains information of one client, including personal and banking attributes, 
and data related to the past interactions with the telemarketer.

The data set presents class imbalance. We will assess during hyper-parameter tuning 
if balancing the class leads to better model.


```{r eda_barchart, fig.align = 'center', echo=FALSE, fig.cap="Figure 1. Class imbalance is observed in the target class. Only 11% of customers reached by the telermarketing campaign accepted the subscription to a new product.", out.width = '60%'}
knitr::include_graphics("../results/eda_barchart_by_target.png")
```


## Model building and selection
Model building process has been carried out in Python 3.9 with the [`scikit-learn`](https://scikit-learn.org/stable/) library. Two models, Random Forest Classifier and Logistic Regression, have been trained under the following conditions:

  * 5-fold [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) results were used for model evaluation
  * Accuracy, f1-score, recall rate, and precision were the metrics selected for model evaluation.
  * Preprocessing of training data:
    - Data was randomized and split based on 80% for training and 20% for testing.
    - All features can be classified into categorical or numeric features. No features were dropped.
    - Missing numeric values are filled using the median. Missing values in categorical features are filled as "missing".
    - All numeric features are scaled using the mean and variance (Standardization)
    - All categorical features are transformed with One-Hot Encoding.
  * Parameters and hyper-parameters tuning.
    - To speed up the training process and ensure reproducibility, the value of `n_jobs` is set to `-1` and `random_state` to `123`.
    - The hyper-parameters are tuned by `RandomizedSearchCV` and the optimal parameter values are chosen based on the f1-score.
    - The baseline accuracy of the model is 88.8% (obtained from the Dummy Classifier using the highest frequency).

### Random Forest Classifier
The best hyper-parameters for the Random Forest are:
```{r Load_RFC_params, echo=FALSE, include=FALSE}
RFC_BestParams <- read_csv("../results/RFC_BestParams.csv")
RFC_BestParams <- RFC_BestParams %>% select(-1) 
```
```{r RFC_params, echo=FALSE}
RFC_BestParams %>%
  kbl(caption = "Table 1. Best hyper-parameters for Random Forest Classifier.") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

```{r conmat_RFC, echo=FALSE, fig.align = 'center', fig.cap="Figure 2. Confusion matrix for Random Forest Classifier on Test data", out.width = '60%'}
knitr::include_graphics("../results/BestRandomForest_ConMat_Test.jpg")
```

```{r RFC_scores, echo=FALSE}
tibble(Accuracy="82.9%",
       Precision="39.7%",
       Recall="96.4%",
       f1="56.2%") %>%
  kbl(caption = "Table 2. Best Random Forest Classifier model scores on validation set:") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```
Random Forest Classifiers trained with the best parameters from hyper-parameter optimization give relatively decent scores on the prediction on validation data. Even though
precision is low, it achieved an excellent recall score.

### Logistic Regression
```{r Load_LR_params, echo=FALSE, include=FALSE}
LR_BestParams <- read_csv("../results/LR_BestParams.csv")
LR_BestParams <- LR_BestParams %>% select(-1) 
```
```{r LR_params, echo=FALSE}
LR_BestParams %>%
  kbl(caption = "Table 4. Best hyper-parameters for Logistic Regression Classifier.") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

```{r conmat_LR, echo=FALSE, fig.align = 'center', fig.cap="Figure 3. Confusion matrix for Logistic Regression on Test data", out.width = '60%'}
knitr::include_graphics("../results/BestLogisticRegression_ConMat_Test.jpg")
```

```{r LR_scores, echo=FALSE}
tibble(Accuracy="86.1%",
       Precision="44.6%",
       Recall="90.3%",
       f1="59.7%") %>%
  kbl(caption = "Table 5. Best Logistic Regression Classifier model scores on validation set:") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```
Logistic Regression overall performs better than the Random Forest Classifier. 

From the results above, we conclude that the Logistic Regression model will be 
the best for predicting customer response to the telemarketing campaign. 
In addition, it provides more interpretable results through the features coefficients.


## Analysis and Results Discussion


```{r load_coef_table, echo=FALSE, include = FALSE}
lr_coeff <- read_csv("../results/BestLogisticRegression_Coefficients.csv") %>% arrange(desc(Coefficient))
colnames(lr_coeff) <- c("Feature","Coefficient")
lr_coeff
```
```{r coeff_barplot, echo=FALSE, fig.align = 'center', fig.cap="Figure 4. Top 10 Coefficients from Logistics Regression Model", out.width = '60%'}
ggplot(lr_coeff[1:10,], aes(x=Coefficient, y=reorder(Feature, Coefficient), fill=Coefficient)) +
  geom_bar(stat="identity", show.legend = FALSE) +
  geom_text(aes(label=round(Coefficient,2)), hjust = 1.3, color="white", size=5.0) +
  theme_classic() +
  labs(x="Coefficient Values",
       y="Features",
       title="Top 10 Coefficients") +
  theme(plot.title=element_text(hjust=0.5, face="bold"),
        axis.title.x=element_text(face="bold"),
        axis.title.y=element_text(face="bold"))
```

As shown in Figure 4, `duration` and `month_mar` have the highest coefficient 
value in the final model. `duration` corresponds to the duration of the call in seconds and 
`month_mar` corresponds to the customer whose last contact date occurred during March. 
We can also see that the campaign achieved better response rates in August and October.

`poutcome_success` indicates previous success with marketing campaign and is tied to the 
idea that a customer that accepted a telemarketing offer in the past may be more likely to
 accept a new one again.

Finally another interesting feature is `cons.price.idx`, which shows up as 
the 3rd more important variable learned by the model. The Consumer Price Index is a quarterly
updated variable that indicates the changes in prices as experienced by consumers. 
When this index is high, then customers may be more open to switching to a new product
for a better price. Even though this may lower the revenue per customer, it still may be
a desired objective for other reasons, such as customer retention. 


### Limitations

Even though there seems to be a better success rate on certain months, we lack of context on the campaign schedule and other environment variables, so at this point we cannot make any inferences regarding those features.

Also, we believe that capturing additional features in the data gathering process, such as the reason of last contact, 
would add valuable information and increase the accuracy of the model.

Lastly, we want to note that the model has been trained with bank customers information that were contacted at least once by the telemarketing agency. As a consequence, it cannot be used to predict the response of new customers.

### Conclusions

Overall the model has stable accuracy and recall rate. Hence, with the correct
variables, the model can identify those who will be likely to respond to the telemarketing
campaign. 
Some additional features, such as the reason for the last contact, could bring additional value to the model
and improve the False Positive rate.

The model developed provides flexibility to prioritize the customers by likelihood of success 
until we reach a desired target or budget. Although, we also recommend assigning weight to the customers
based on their banking/personal profile. 
This categorization should be defined by the bank and 
must be aligned with the objective of the particular campaign. 


## References
